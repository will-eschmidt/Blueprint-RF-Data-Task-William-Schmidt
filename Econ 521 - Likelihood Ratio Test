{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cleared-ending",
   "metadata": {},
   "source": [
    "<center><h1> Assignment 4</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-conclusion",
   "metadata": {},
   "source": [
    "**Author(s):**\n",
    "1. Will Schmidt (will.schmidt@emory.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-sheep",
   "metadata": {},
   "source": [
    "**Objectives**: This <ins>empirical</ins> exercise aims at\n",
    " 1. Making students program a likelihood function in Pyhon using a *Jupyter Notebook*;\n",
    " 2. Use *GitHub* to retrieve and submit computer code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-questionnaire",
   "metadata": {},
   "source": [
    "👉🏼 Prior to attempting to do this exercise, please read and _understand_ the `Ch5_python.ipynb` notebook in this repository that provides a Python implementation of the Stata code discussed in the lectures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-rainbow",
   "metadata": {},
   "source": [
    "3. Consider the Normal Regression Model discussed in the lectures where wage$=\\mathbb{E}[$wage$|\\newline $education, experience$]+e$, $e|$education, experience$\\sim\n",
    "N(0,\\sigma^{2})$, and $\\mathbb{E}[$wage$|$education, experience$]=\\beta_{1}$education$+\\beta_{2}$experience$+\\beta_{3}$exp2$+\\beta_{4}$. Recall that exp2$=$experience$^2$/100. This model was\n",
    "estimated via maximum likelihood using the 2,133 sub-sample of married, non-white, females in the [cps09mar](https://www.ssc.wisc.edu/~bhansen/econometrics/cps09mar.dta) data set in the Lecture Notes. Using Python, perform a likelihood-ratio test for the hypothesis, $\\mathbb{H}_{0}:\\beta_1=0.12,\\text{ }\\beta_2=0$, vs. $\\mathbb{H}_{1}:$ Not $\\mathbb{H}_0$. [50 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "likely-shell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.803018\n",
      "         Iterations: 464\n",
      "         Function evaluations: 760\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.804208\n",
      "         Iterations: 98\n",
      "         Function evaluations: 190\n",
      "LR = 5.077301247313244\n",
      "Prob > LR = 0.07897289207776781\n"
     ]
    }
   ],
   "source": [
    "#Import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import patsy\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "\n",
    "#Creating the log ratiohood function \n",
    "def log_norm(y, X, β, σ):\n",
    "    \n",
    "    xβ =  X.dot(β)\n",
    "    \n",
    "    return stats.norm.logpdf(y,xβ,σ).sum() \n",
    "\n",
    "class ml_ols(GenericLikelihoodModel):\n",
    "    \n",
    "    def __init__(self, endog, exog, **kwds):\n",
    "        super(ml_ols, self).__init__(endog, exog, **kwds)\n",
    "        \n",
    "    def nloglikeobs(self, params):\n",
    "        σ = params[-1]\n",
    "        β = params[:-1]\n",
    "        ll = log_norm(self.endog, self.exog, β, σ)\n",
    "        return -ll\n",
    "    \n",
    "    def fit(self, start_params=None, maxiter=10000, maxfun=5000, **kwds):\n",
    "        \n",
    "        # we have one additional parameter and we need to add it for summary\n",
    "        self.exog_names.append('σ')\n",
    "        #self.exog_names.append('sigma')\n",
    "\n",
    "        if start_params == None:\n",
    "            # Reasonable starting values\n",
    "            start_params = np.append(np.ones(self.exog.shape[1]), 0.5)\n",
    "            \n",
    "        return super(ml_ols, self).fit(start_params=start_params,maxiter=maxiter, maxfun=maxfun,**kwds)\n",
    "\n",
    "#load the data into our workspace\n",
    "cps09mr = pd.read_stata('https://www.ssc.wisc.edu/~bhansen/econometrics/cps09mar.dta')\n",
    "\n",
    "#Create relevant variables\n",
    "cps09mr['wage'] = np.log(cps09mr.earnings/(cps09mr.hours*cps09mr.week))\n",
    "cps09mr['experience'] = cps09mr.age - cps09mr.education - 6\n",
    "cps09mr['exp2'] = (cps09mr.experience**2)/100\n",
    "cps09mr['mnwf'] = np.logical_and(np.logical_and(cps09mr.marital<=2, cps09mr.race!=1), cps09mr.female==1)\n",
    "\n",
    "#Create a formula, f_u and f_r, for our unrestricted and restricted model \n",
    "f_u = 'wage ~ education + experience + exp2'\n",
    "y1, X_u = patsy.dmatrices(f_u, data=cps09mr.loc[cps09mr['mnwf']], return_type='dataframe')\n",
    "unrestricted = ml_ols(y1,X_u).fit()\n",
    "\n",
    "#create adjusted wage tha corrects for a 0.12 parameter \n",
    "cps09mr['adj_wage'] = cps09mr['wage'] - 0.12*cps09mr['education']\n",
    "#we could also do f_r = 'I(wage - 0.12*education) ~ exp2'\n",
    "\n",
    "\n",
    "f_r = 'adj_wage ~ exp2'\n",
    "y2, X_r = patsy.dmatrices(f_r, data=cps09mr.loc[cps09mr['mnwf']], return_type='dataframe')\n",
    "restricted = ml_ols(y2,X_r).fit()\n",
    "\n",
    "#define and save some necessary values \n",
    "u_ll = unrestricted.llf\n",
    "u_k =len(unrestricted.params)\n",
    "r_ll = restricted.llf\n",
    "r_k =len(restricted.params)\n",
    "\n",
    "#Perform the log ratiohood test\n",
    "lr = 2*(u_ll-r_ll)\n",
    "print('LR =',lr)\n",
    "print('Prob > LR =', 1-stats.chi2.cdf(lr,u_k-r_k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8449da0d-eada-45c3-867b-d2a50e198075",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since Prob > LR is greater than our critical value of 0.05, we fail to reject the null hypothesis at the 5 percent level\n",
    "#of siginficance"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
